{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.contrib import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlowLinearClassifier class is deprecated. Please consider using LinearClassifier as an alternative.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp071sRS\n",
      "WARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(784)]), is_sparse=False)\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.uint8, shape=TensorShape([Dimension(None)]), is_sparse=False)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target's dtype should be int32, int64 or compatible. Instead got <dtype: 'uint8'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0d31422ac7a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mfeature_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     learning_rate=0.01)\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m score = metrics.accuracy_score(\n\u001b[1;32m     21\u001b[0m     mnist.test.labels, classifier.predict(mnist.test.images))\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, steps, batch_size, monitors, logdir)\u001b[0m\n\u001b[1;32m    468\u001b[0m     return super(DeprecatedMixin, self).fit(\n\u001b[1;32m    469\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         batch_size=batch_size or self.batch_size, monitors=monitors)\n\u001b[0m\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m   def predict(self, x=None, input_fn=None, batch_size=None, outputs=None,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[1;32m    238\u001b[0m                              \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                              \u001b[0mmonitors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmonitors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m                              max_steps=max_steps)\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, steps, feed_fn, init_op, init_feed_fn, init_fn, device_fn, monitors, log_every_steps, fail_on_nan_loss, max_steps)\u001b[0m\n\u001b[1;32m    548\u001b[0m       \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m       \u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_train_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m       \u001b[0;31m# Add default monitors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/linear.pyc\u001b[0m in \u001b[0;36m_get_train_ops\u001b[0;34m(self, features, targets)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_linear_feature_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linear_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdca_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSDCAOptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLinearClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_train_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# SDCA currently supports binary classification only.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.pyc\u001b[0m in \u001b[0;36m_get_train_ops\u001b[0;34m(self, features, targets)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_centered_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m       \u001b[0mcentered_bias_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_centered_bias_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m       \u001b[0mcentered_bias_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.pyc\u001b[0m in \u001b[0;36m_centered_bias_step\u001b[0;34m(self, targets, features)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentered_bias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         [batch_size, self._target_column.num_label_columns])\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;31m# Learn central bias by an optimizer. 0.1 is a convervative lr for a single\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;31m# variable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/target_column.pyc\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, logits, target, features)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \"\"\"\n\u001b[1;32m    178\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0mloss_unweighted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0mweight_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weight_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/target_column.pyc\u001b[0m in \u001b[0;36m_softmax_cross_entropy_loss\u001b[0;34m(logits, target)\u001b[0m\n\u001b[1;32m    354\u001b[0m       not target.dtype.is_compatible_with(dtypes.int32)):\n\u001b[1;32m    355\u001b[0m     raise ValueError(\"Target's dtype should be int32, int64 or compatible. \"\n\u001b[0;32m--> 356\u001b[0;31m                      \"Instead got %s.\" % target.dtype)\n\u001b[0m\u001b[1;32m    357\u001b[0m   \u001b[0;31m# sparse_softmax_cross_entropy_with_logits requires [batch_size] target.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target's dtype should be int32, int64 or compatible. Instead got <dtype: 'uint8'>."
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "\n",
    "### Download and load MNIST data.\n",
    "\n",
    "mnist = learn.datasets.load_dataset('mnist')\n",
    "\n",
    "### Linear classifier.\n",
    "\n",
    "feature_columns = learn.infer_real_valued_columns_from_input(mnist.train.images)\n",
    "classifier = learn.TensorFlowLinearClassifier(\n",
    "    feature_columns=feature_columns, n_classes=10, batch_size=100, steps=1000,\n",
    "    learning_rate=0.01)\n",
    "classifier.fit(mnist.train.images, mnist.train.labels)\n",
    "score = metrics.accuracy_score(\n",
    "    mnist.test.labels, classifier.predict(mnist.test.images))\n",
    "print('Accuracy: {0:f}'.format(score))\n",
    "\n",
    "### Convolutional network\n",
    "\n",
    "\n",
    "def max_pool_2x2(tensor_in):\n",
    "  return tf.nn.max_pool(\n",
    "      tensor_in, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def conv_model(X, y):\n",
    "  # pylint: disable=invalid-name,missing-docstring\n",
    "  # reshape X to 4d tensor with 2nd and 3rd dimensions being image width and\n",
    "  # height final dimension being the number of color channels.\n",
    "  X = tf.reshape(X, [-1, 28, 28, 1])\n",
    "  # first conv layer will compute 32 features for each 5x5 patch\n",
    "  with tf.variable_scope('conv_layer1'):\n",
    "    h_conv1 = learn.ops.conv2d(X, n_filters=32, filter_shape=[5, 5],\n",
    "                               bias=True, activation=tf.nn.relu)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "  # second conv layer will compute 64 features for each 5x5 patch.\n",
    "  with tf.variable_scope('conv_layer2'):\n",
    "    h_conv2 = learn.ops.conv2d(h_pool1, n_filters=64, filter_shape=[5, 5],\n",
    "                               bias=True, activation=tf.nn.relu)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "    # reshape tensor into a batch of vectors\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n",
    "  # densely connected layer with 1024 neurons.\n",
    "  h_fc1 = learn.ops.dnn(\n",
    "      h_pool2_flat, [1024], activation=tf.nn.relu, dropout=0.5)\n",
    "  return learn.models.logistic_regression(h_fc1, y)\n",
    "\n",
    "# Training and predicting.\n",
    "classifier = learn.TensorFlowEstimator(\n",
    "    model_fn=conv_model, n_classes=10, batch_size=100, steps=20000,\n",
    "    learning_rate=0.001)\n",
    "classifier.fit(mnist.train.images, mnist.train.labels)\n",
    "score = metrics.accuracy_score(\n",
    "    mnist.test.labels, classifier.predict(mnist.test.images))\n",
    "print('Accuracy: {0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist_train_labels = mnist.train.labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlowLinearClassifier class is deprecated. Please consider using LinearClassifier as an alternative.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpudgzvr\n",
      "WARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(784)]), is_sparse=False)\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int32, shape=TensorShape([Dimension(None)]), is_sparse=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.889200\n"
     ]
    }
   ],
   "source": [
    "feature_columns = learn.infer_real_valued_columns_from_input(mnist.train.images)\n",
    "classifier = learn.TensorFlowLinearClassifier(\n",
    "    feature_columns=feature_columns, n_classes=10, batch_size=100, steps=1000,\n",
    "    learning_rate=0.01)\n",
    "classifier.fit(mnist.train.images, mnist_train_labels)\n",
    "score = metrics.accuracy_score(\n",
    "    mnist.test.labels, classifier.predict(mnist.test.images))\n",
    "print('Accuracy: {0:f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpY9kvC1\n",
      "WARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(784)]), is_sparse=False)\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False)\n",
      "INFO:tensorflow:Create CheckpointSaver\n",
      "INFO:tensorflow:Step 1: loss = 2.57975\n",
      "INFO:tensorflow:Step 101: loss = 2.50789\n",
      "INFO:tensorflow:Step 201: loss = 2.27466\n",
      "INFO:tensorflow:Saving checkpoints for 300 into /tmp/tmpY9kvC1/model.ckpt.\n",
      "INFO:tensorflow:Step 301: loss = 2.11321\n",
      "INFO:tensorflow:Step 401: loss = 1.99002\n",
      "INFO:tensorflow:Step 501: loss = 1.76649\n",
      "INFO:tensorflow:Saving checkpoints for 600 into /tmp/tmpY9kvC1/model.ckpt.\n",
      "INFO:tensorflow:Step 601: loss = 1.43426\n",
      "INFO:tensorflow:Step 701: loss = 1.27391\n",
      "INFO:tensorflow:Step 801: loss = 1.00421\n",
      "INFO:tensorflow:Saving checkpoints for 900 into /tmp/tmpY9kvC1/model.ckpt.\n",
      "INFO:tensorflow:Step 901: loss = 0.733193\n",
      "INFO:tensorflow:Step 1001: loss = 0.686502\n",
      "INFO:tensorflow:Step 1101: loss = 0.725624\n",
      "INFO:tensorflow:Saving checkpoints for 1200 into /tmp/tmpY9kvC1/model.ckpt.\n",
      "INFO:tensorflow:Step 1201: loss = 0.590115\n",
      "INFO:tensorflow:Step 1301: loss = 0.603186\n",
      "INFO:tensorflow:Step 1401: loss = 0.428882\n",
      "INFO:tensorflow:Saving checkpoints for 1500 into /tmp/tmpY9kvC1/model.ckpt.\n",
      "INFO:tensorflow:Step 1501: loss = 0.461058\n",
      "INFO:tensorflow:Step 1601: loss = 0.420942\n",
      "INFO:tensorflow:Step 1701: loss = 0.619975\n",
      "INFO:tensorflow:Saving checkpoints for 1800 into /tmp/tmpY9kvC1/model.ckpt.\n",
      "INFO:tensorflow:Step 1801: loss = 0.483243\n",
      "INFO:tensorflow:Step 1901: loss = 0.306577\n",
      "INFO:tensorflow:Step 2001: loss = 0.622212\n",
      "INFO:tensorflow:Saving checkpoints for 2100 into /tmp/tmpY9kvC1/model.ckpt.\n",
      "INFO:tensorflow:Step 2101: loss = 0.410275\n",
      "INFO:tensorflow:Step 2201: loss = 0.398326\n",
      "INFO:tensorflow:Step 2301: loss = 0.44535\n",
      "INFO:tensorflow:Saving checkpoints for 2400 into /tmp/tmpY9kvC1/model.ckpt.\n",
      "INFO:tensorflow:Step 2401: loss = 0.373543\n",
      "INFO:tensorflow:Step 2501: loss = 0.474368\n",
      "INFO:tensorflow:Step 2601: loss = 0.321189\n",
      "INFO:tensorflow:Saving checkpoints for 2700 into /tmp/tmpY9kvC1/model.ckpt.\n",
      "INFO:tensorflow:Step 2701: loss = 0.358166\n",
      "INFO:tensorflow:Step 2801: loss = 0.313319\n",
      "INFO:tensorflow:Step 2901: loss = 0.337152\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into /tmp/tmpY9kvC1/model.ckpt.\n",
      "INFO:tensorflow:Step 3001: loss = 0.392718\n",
      "INFO:tensorflow:Step 3101: loss = 0.292396\n",
      "INFO:tensorflow:Step 3201: loss = 0.231825\n",
      "INFO:tensorflow:Saving checkpoints for 3300 into /tmp/tmpY9kvC1/model.ckpt.\n",
      "INFO:tensorflow:Step 3301: loss = 0.235468\n",
      "INFO:tensorflow:Step 3401: loss = 0.289203\n",
      "INFO:tensorflow:Step 3501: loss = 0.332811\n",
      "INFO:tensorflow:Saving checkpoints for 3600 into /tmp/tmpY9kvC1/model.ckpt.\n",
      "INFO:tensorflow:Step 3601: loss = 0.332304\n",
      "INFO:tensorflow:Step 3701: loss = 0.251938\n",
      "INFO:tensorflow:Step 3801: loss = 0.255134\n",
      "INFO:tensorflow:Saving checkpoints for 3900 into /tmp/tmpY9kvC1/model.ckpt.\n",
      "INFO:tensorflow:Step 3901: loss = 0.246882\n",
      "INFO:tensorflow:Step 4001: loss = 0.164985\n",
      "INFO:tensorflow:Step 4101: loss = 0.4014\n",
      "INFO:tensorflow:Saving checkpoints for 4200 into /tmp/tmpY9kvC1/model.ckpt.\n",
      "INFO:tensorflow:Step 4201: loss = 0.234254\n",
      "INFO:tensorflow:Step 4301: loss = 0.217518\n",
      "INFO:tensorflow:Step 4401: loss = 0.299076\n",
      "INFO:tensorflow:Saving checkpoints for 4500 into /tmp/tmpY9kvC1/model.ckpt.\n",
      "INFO:tensorflow:Step 4501: loss = 0.202452\n",
      "INFO:tensorflow:Step 4601: loss = 0.297563\n",
      "INFO:tensorflow:Step 4701: loss = 0.34585\n",
      "INFO:tensorflow:Saving checkpoints for 4800 into /tmp/tmpY9kvC1/model.ckpt.\n",
      "INFO:tensorflow:Step 4801: loss = 0.268202\n",
      "INFO:tensorflow:Step 4901: loss = 0.160126\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpY9kvC1/model.ckpt.\n",
      "INFO:tensorflow:Loading model from checkpoint: /tmp/tmpY9kvC1/model.ckpt-5000-?????-of-00001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.930000\n"
     ]
    }
   ],
   "source": [
    "def max_pool_2x2(tensor_in):\n",
    "  return tf.nn.max_pool(\n",
    "      tensor_in, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def conv_model(X, y):\n",
    "  # pylint: disable=invalid-name,missing-docstring\n",
    "  # reshape X to 4d tensor with 2nd and 3rd dimensions being image width and\n",
    "  # height final dimension being the number of color channels.\n",
    "  X = tf.reshape(X, [-1, 28, 28, 1])\n",
    "  # first conv layer will compute 32 features for each 5x5 patch\n",
    "  with tf.variable_scope('conv_layer1'):\n",
    "    h_conv1 = tf.contrib.layers.conv2d(X, num_outputs=32, kernel_size=[5, 5])\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "  # second conv layer will compute 64 features for each 5x5 patch.\n",
    "  with tf.variable_scope('conv_layer2'):\n",
    "    h_conv2 = tf.contrib.layers.conv2d(h_pool1, num_outputs=64, kernel_size=[5, 5])\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "    # reshape tensor into a batch of vectors\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n",
    "    \n",
    "  # densely connected layer with 1024 neurons.\n",
    "  normalizer_fn = layers.dropout\n",
    "  normalizer_params = {'keep_prob': 0.5}\n",
    "  h_fc1 = layers.stack(\n",
    "      h_pool2_flat, layers.fully_connected, [1024],\n",
    "        normalizer_fn=normalizer_fn,\n",
    "        normalizer_params=normalizer_params)\n",
    "    \n",
    "  return learn.models.logistic_regression(h_fc1, y)\n",
    "\n",
    "# Training and predicting.\n",
    "classifier = learn.TensorFlowEstimator(\n",
    "    model_fn=conv_model, n_classes=10, batch_size=100, steps=5000,\n",
    "    learning_rate=0.001)\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "classifier.fit(mnist.train.images, mnist.train.labels)\n",
    "score = metrics.accuracy_score(\n",
    "    mnist.test.labels, classifier.predict(mnist.test.images))\n",
    "print('Accuracy: {0:f}'.format(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
